# üöÄ Pipeline ETL Complet - Python Data Processing

Un site web statique interactif et p√©dagogique pr√©sentant en d√©tail l'impl√©mentation compl√®te d'un pipeline Extract-Transform-Load (ETL) en Python avec pandas, numpy, seaborn et matplotlib.

## üìã Sommaire

- [Vue d'ensemble](#vue-densemble)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Structure du projet](#structure-du-projet)
- [Installation et utilisation](#installation-et-utilisation)
- [Documentation d√©taill√©e](#documentation-d√©taill√©e)
- [Visualisations](#visualisations)
- [Technologies utilis√©es](#technologies-utilis√©es)
- [Contribution](#contribution)

## üéØ Vue d'ensemble

Ce projet est une impl√©mentation compl√®te et d√©taill√©e d'un pipeline ETL en Python, pr√©sent√©e sous forme d'un site web interactif et √©ducatif. Il couvre tous les aspects du traitement des donn√©es : extraction, transformation, nettoyage, analyse et export.

### Objectifs p√©dagogiques
- Comprendre les concepts fondamentaux du pipeline ETL
- Ma√Ætriser les techniques avanc√©es de manipulation de donn√©es avec pandas
- Apprendre √† d√©tecter et traiter les valeurs aberrantes
- Cr√©er des features d√©riv√©es pour l'analyse de donn√©es
- Exporter des donn√©es vers diff√©rents formats avec mise en forme

## ‚ú® Fonctionnalit√©s

### 1. Extraction des donn√©es
- **Lecture multi-fichiers CSV** : Gestion de fichiers avec diff√©rents encodages et formats
- **D√©tection automatique** : D√©tection intelligente de l'encodage et des s√©parateurs
- **Gestion des erreurs** : Syst√®me robuste de gestion des erreurs de lecture

### 2. Transformation des donn√©es
- **Fusion des datasets** : Utilisation de `pd.concat()` et `pd.merge()`
- **Standardisation** : Uniformisation des colonnes et des types de donn√©es
- **Nettoyage avanc√©** : Gestion des valeurs manquantes avec diff√©rentes strat√©gies

### 3. D√©tection des outliers
- **M√©thode IQR** : D√©tection bas√©e sur l'intervalle interquartile
- **Strat√©gies de traitement** : Capping, suppression ou transformation
- **Analyse statistique** : Rapport d√©taill√© sur les outliers d√©tect√©s

### 4. Features d√©riv√©es
- **Statistiques par groupe** : Moyenne, m√©diane, √©cart-type par cat√©gorie
- **Ratios et proportions** : Cr√©ation de variables ratio
- **Features polynomiales** : Utilisation de PolynomialFeatures de sklearn
- **Composantes principales** : PCA pour la r√©duction de dimensionnalit√©

### 5. Export des donn√©es
- **CSV** : Export avec compression et gestion des gros fichiers
- **Excel** : Export avec mise en forme professionnelle
- **Formatage conditionnel** : Color scales, data bars et icon sets

### 6. Visualisations interactives
- **Chart.js** : Graphiques anim√©s et interactifs
- **Distribution des donn√©es** : Histogrammes et diagrammes en barres
- **Corr√©lation** : Matrices de corr√©lation et graphiques en ligne
- **Outliers** : Diagrammes en secteur pour la r√©partition

## üìÅ Structure du projet

```
pipeline-etl-website/
‚îú‚îÄ‚îÄ index.html              # Page principale avec toutes les sections
‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îî‚îÄ‚îÄ style.css          # Styles modernes et responsive
‚îú‚îÄ‚îÄ js/
‚îÇ   ‚îî‚îÄ‚îÄ main.js            # JavaScript interactif et animations
‚îî‚îÄ‚îÄ README.md              # Documentation compl√®te
```

## üöÄ Installation et utilisation

### Pr√©requis
- Un navigateur web moderne (Chrome, Firefox, Safari, Edge)
- Connexion internet (pour les CDN)

### Installation
1. Clonez le d√©p√¥t ou t√©l√©chargez les fichiers
2. Ouvrez `index.html` dans votre navigateur
3. Explorez les diff√©rentes sections du pipeline ETL

### Utilisation
- **Navigation** : Utilisez la barre de navigation fixe pour acc√©der aux diff√©rentes sections
- **Code Python** : Copiez le code directement depuis les blocs de code
- **Visualisations** : Interagissez avec les graphiques Chart.js
- **Mode sombre** : Activez le mode sombre avec le bouton en haut √† droite

## üìö Documentation d√©taill√©e

### Les 4 datasets utilis√©s

#### 1. Titanic Dataset
- **Taille** : ~891 lignes √ó 12 colonnes
- **Colonnes** : PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked
- **Utilisation** : Classification binaire (survie/passage)
- **Source** : Kaggle Titanic competition

#### 2. Iris Dataset
- **Taille** : 150 lignes √ó 5 colonnes
- **Colonnes** : sepal_length, sepal_width, petal_length, petal_width, species
- **Utilisation** : Classification multiclasse (3 esp√®ces d'iris)
- **Source** : Fisher's Iris dataset

#### 3. Amazon Bestsellers Books
- **Taille** : ~2000+ lignes √ó 7 colonnes
- **Colonnes** : Name, Author, User Rating, Reviews, Price, Year, Genre
- **Utilisation** : Analyse de tendances et recommandation
- **Source** : Kaggle Amazon bestsellers

#### 4. Weather Data 2018-2022
- **Taille** : ~1800+ lignes √ó 6 colonnes
- **Colonnes** : date, temperature, humidity, precipitation, windspeed, location
- **Utilisation** : S√©ries temporelles et pr√©visions m√©t√©o
- **Source** : Donn√©es m√©t√©orologiques historiques

### Extraction des donn√©es

```python
def extraire_donnees(self, chemins_fichiers):
    """
    Extrait les donn√©es de plusieurs fichiers CSV
    """
    for nom, chemin in chemins_fichiers.items():
        try:
            # D√©tection automatique de l'encodage
            df = self._lire_csv_avec_encodage(chemin)
            self.data[nom] = df
            print(f"‚úÖ {nom}: {df.shape[0]} lignes, {df.shape[1]} colonnes")
        except Exception as e:
            print(f"‚ùå Erreur extraction {nom}: {e}")
            raise
```

### Nettoyage des valeurs manquantes

```python
def nettoyer_valeurs_manquantes(self, df, strategy='median'):
    """
    Nettoie les valeurs manquantes en utilisant la strat√©gie sp√©cifi√©e
    """
    df_clean = df.copy()
    missing_cols = df_clean.columns[df_clean.isnull().any()].tolist()
    
    for col in missing_cols:
        if df_clean[col].dtype in ['int64', 'float64']:
            if strategy == 'median':
                median_value = df_clean[col].median()
                df_clean[col].fillna(median_value, inplace=True)
                print(f"‚úÖ {col}: Valeurs manquantes remplac√©es par la m√©diane ({median_value:.2f})")
    
    return df_clean
```

### D√©tection des outliers (IQR)

```python
def detecter_outliers_iqr(self, df, columns=None, multiplier=1.5):
    """
    D√©tecte les outliers en utilisant la m√©thode IQR
    """
    outliers_info = {}
    numeric_cols = columns or df.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        # Limites de d√©tection
        lower_bound = Q1 - multiplier * IQR
        upper_bound = Q3 + multiplier * IQR
        
        # Identification des outliers
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        
        outliers_info[col] = {
            'Q1': Q1, 'Q3': Q3, 'IQR': IQR,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound,
            'outliers_count': len(outliers)
        }
    
    return outliers_info
```

### Export Excel avec mise en forme

```python
def exporter_excel_formate(self, df, chemin_sortie, nom_feuille='Donn√©es'):
    """
    Exporte vers Excel avec mise en forme professionnelle
    """
    with pd.ExcelWriter(chemin_sortie, engine='xlsxwriter') as writer:
        # √âcrire les donn√©es
        df.to_excel(writer, sheet_name=nom_feuille, index=False)
        
        # Formater l'en-t√™te
        workbook = writer.book
        worksheet = writer.sheets[nom_feuille]
        
        header_format = workbook.add_format({
            'bold': True,
            'text_wrap': True,
            'valign': 'top',
            'fg_color': '#D7E4BC',
            'border': 1
        })
        
        # Appliquer le format d'en-t√™te
        for col_num, value in enumerate(df.columns.values):
            worksheet.write(0, col_num, value, header_format)
        
        # Ajustement automatique de la largeur des colonnes
        for i, col in enumerate(df.columns):
            max_length = max(df[col].astype(str).map(len).max(), len(col)) + 2
            worksheet.set_column(i, i, min(max_length, 50))
```

## üìä Visualisations

### Graphiques inclus
1. **Distribution des datasets** : Diagramme en barres montrant la taille de chaque dataset
2. **Performance du pipeline** : Graphique en ligne montrant le temps d'ex√©cution de chaque √©tape
3. **R√©partition des outliers** : Diagramme en secteur montrant le pourcentage d'outliers d√©tect√©s

### Interactivit√©
- **Animations** : Tous les graphiques sont anim√©s avec des transitions fluides
- **Responsive** : Les graphiques s'adaptent √† la taille de l'√©cran
- **Tooltips** : Informations d√©taill√©es au survol des points de donn√©es
- **L√©gendes** : L√©gendes interactives pour filtrer les s√©ries

## üõ† Technologies utilis√©es

### Frontend
- **HTML5** : Structure s√©mantique moderne
- **CSS3** : Styles avanc√©s avec variables CSS et animations
- **JavaScript ES6+** : Interactivit√© et animations
- **Bootstrap 5** : Framework CSS responsive
- **Chart.js** : Visualisations de donn√©es interactives
- **Prism.js** : Coloration syntaxique du code Python

### Biblioth√®ques Python (dans le code)
- **pandas** : Manipulation et analyse de donn√©es
- **numpy** : Calculs num√©riques
- **seaborn** : Visualisations statistiques
- **matplotlib** : Graphiques et visualisations
- **scikit-learn** : Features engineering et preprocessing

### Outils de d√©veloppement
- **Git** : Contr√¥le de version
- **VS Code** : √âditeur de code
- **Chrome DevTools** : D√©bogage et optimisation

## ü§ù Contribution

Les contributions sont les bienvenues ! Voici comment contribuer :

### Rapport de bugs
1. Cr√©ez une issue d√©crivant le bug
2. Incluez les √©tapes pour reproduire le probl√®me
3. Ajoutez des captures d'√©cran si pertinent

### Propositions d'am√©lioration
1. Fork le projet
2. Cr√©ez une branche pour votre fonctionnalit√©
3. Commitez vos changements
4. Push vers la branche
5. Ouvrez une Pull Request

### Am√©liorations sugg√©r√©es
- [ ] Ajouter plus de datasets (Bitcoin, COVID-19, etc.)
- [ ] Impl√©menter des algorithmes de machine learning
- [ ] Ajouter des tests unitaires pour le code Python
- [ ] Cr√©er une version interactive avec Jupyter Notebook
- [ ] Ajouter des exemples de dashboard avec Plotly
- [ ] Impl√©menter le streaming de donn√©es en temps r√©el

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de d√©tails.

## üôè Remerciements

- **Kaggle** pour les datasets
- **Chart.js** pour les visualisations interactives
- **Bootstrap** pour le framework CSS
- **Prism.js** pour la coloration syntaxique
- **La communaut√© open source** pour les biblioth√®ques Python

## üìû Contact

Pour toute question ou suggestion, n'h√©sitez pas √† ouvrir une issue ou √† contribuer au projet.

---

**‚≠ê Si ce projet vous est utile, n'h√©sitez pas √† lui donner une √©toile !** ‚≠ê
